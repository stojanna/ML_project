{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347c0f22",
   "metadata": {},
   "source": [
    "# Online Passive-Aggressive Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e6d835",
   "metadata": {},
   "source": [
    "## Teorijski uvod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7582a6f",
   "metadata": {},
   "source": [
    "Posmatrajmo sledeće tri postavke problema odlučivanja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229665b",
   "metadata": {},
   "source": [
    "<img src='assets/three_decision_problems.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1822a10",
   "metadata": {},
   "source": [
    "Počnimo sa klasifikacijom gde imamo instance iz $R^n$ i vrednosti ciljne promenljive. Cilj je pronaći hiperravan koja razdvaja\n",
    "pozitivne i negativne instance tj. želimo da $y_tw * x_t$ ima veliku pozitivnu vrednost, gde pod veliko mislimo na bar $\\epsilon$.\n",
    "Označimo uređeni par instance i odgovarajuće vrednosti ciljne promenljive sa $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ab33e",
   "metadata": {},
   "source": [
    "Prilikom regresije instance su takođe iz $R^n$ ali predviđamo realne brojeve koristeći linearnu funkciju $w*x_t$. Ovde \n",
    "$\\epsilon$ meri tačnost našeg predviđanja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ae5f4",
   "metadata": {},
   "source": [
    "Kod treće postavke problema odlučivanja ciljamo na vektore iz $R^n$ tj. predviđamo $w$ i $\\epsilon$ jeponovo parametar tačnosti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d862c26",
   "metadata": {},
   "source": [
    "Pretpostavimo sada da podatke dobijamo u online režimu tj. sekvencijalno, a ne sve odjednom na gomili. U ovom slučaju potrebno \n",
    "je izvući informacije iz trenutnih podataka i ažurirati prethodno sakupljene informacije. Pogledajmo sada kako to primeniti u \n",
    "tri prethodno navedena problema. Klasifikacija je predstavljena crnom bojom, regresija plavom i treći problem crvenom bojom. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21a1084",
   "metadata": {},
   "source": [
    "<img src='assets/online_setting.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0859ce5a",
   "metadata": {},
   "source": [
    "U slučaju klasifikacije u svakom koraku dobijamo instancu $x_t$ i predviđamo znak ciljne promenljive koristeći znanje $w_t$ koje smo do tada sakupili. Zatim dobijamo pravu vrednost ciljne promenljive i trpimo trenutni gubitak koji je jednak odstupanju našeg predviđanja od stvarne vrednosti ciljne promenljive. Cilj je da ukupni gubitak bude što manji, odnosno, želimo da ne samo predviđamo tačno, već i sa velikom sigurnošću $|w_t*x_t|$. Na kraju, ažuriramo $w_t$ koristeći trenutni uređeni par $(x_t,y_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476be64",
   "metadata": {},
   "source": [
    "Slično se ponašamo i u ostala dva slučaja. Kod regresije naše predviđanje je $w_t*x_t$ i trpimo gubitak u vrednosti odstupanja od prave vrednosti ciljne promenljive. Treći slučaj je malo drugačiji jer nemamo instancu $x_t$, naše predviđanje je $w_t$ i nadamo se da će se $y_t$ naći u njegovoj $\\epsilon$ okolini. Ponovo trpimo gubitak jednak rastojanju između $y_t$ i $w_t$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e89119",
   "metadata": {},
   "source": [
    "Primetimo da gore navedena tri postupka imaju zajedničkih elemenata koje možemo predstaviti na sledeći način. Neka je $\\delta$ u slučaju klasifikacije označena sigurnost predviđanja pri $w_t$ u primeru sa $z_t$, a u ostala dva slučaja odstupanje predviđanja od prave vrednosti ciljne promenljive. Za funkciju gubitka uzimamo funkciju u obliku šarke tj. linearno kažnjavamo odstupanje od $\\epsilon$. Sve radimo pod pretpostavkom izvodljivosti tj. postoje $w^*$ i $\\epsilon^*$ takvi da za svako $t$ važi da je trenutno odstupanje $\\delta$ najviše $\\epsilon^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36042cac",
   "metadata": {},
   "source": [
    "<img src='assets/unified_view.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed598cf",
   "metadata": {},
   "source": [
    "Imajući u vidu prethodno zajedničko predstavljanje sva tri problema, razmotrimo ponovo implementaciju algoritma. Sa svakim novim primerom $z_t$ dobijamo skup $C$ vektora $w$ koji nemaju gubitaka pri obradi ovog primera. Za klasifikaciju, $C$ je poluprostor, za regresiju $C$ je hiperravan, a u trećem slučaju $C$ je sfera sa centrom u $y_t$. Kako je $\\delta$ konveksna funkcija, $C$ je konveksan skup. Želimo da novo stanje $w_{t+1}$ bude sto je moguće bliže prethodnom stanju $w_t$ pri nametanju uslova da nema gubitka na trenutnom primeru tj. da $w_{t+1}$ pripada skupu $C$. Zaključujemo da će takvo $w_{t+1}$ biti projekcija $w_t$ na skup $C$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dd2254",
   "metadata": {},
   "source": [
    "<img src='assets/projection.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d1edbe",
   "metadata": {},
   "source": [
    "Analitičko rešenje je prikazano na slici ispod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c371701",
   "metadata": {},
   "source": [
    "<img src='assets/analytic_solution.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0e31c",
   "metadata": {},
   "source": [
    "Ako pri trenutnom primeru $z_t$ ne dolazi do greške u predviđanju, ne ažuriramo $w_t$, tj. $w_{t+1}=w_t$ i zato algoritam nazivamo pasivnim. U suprotnom, namećemo uslov da nema greške na trenutnom primeru i dobijamo novo $w_{t+1}$ i zato algoritam nazivamo agresivnim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844daf1",
   "metadata": {},
   "source": [
    "<img src='assets/passive_aggressive.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40b286",
   "metadata": {},
   "source": [
    "Dosadašnje razmatranje koristi agresivnu strategiju za ažuriranje vektora $w_t$ sve dok se novim stanjem $w_{t+1}$ ne postigne da nema gubitka na trenutnom primeru tj. primenjuje se `hard magin` pristip. Međutim, to može imati neželjene posledice u slučaju šuma ili pogrešnih vrednosti ciljne promenljive jer primorava PA algoritam da drastično promeni težinski vektor u pogrešnom pravcu. Ovaj problem se može ublažiti primenom `soft margin` pristupa tj. oslabljivanjem uslova za vektor $w$ prilikom minimizacije. Sada želimo da greška bude manja od neke pozitivne vrednosti $\\xi$, a ne da je jednaka nuli kao ranije. Ovo utiče i na optimizacioni problem pa, u zavisnosti od toga da li dodajemo $\\xi$ ili $\\xi^2$, dobijamo dve modifikacije algoritma `PA-I` i `PA-II`, redom. Jačinu uticaja dodatog člana određujemo regularizacionim hiperparametrom `C` tj. parametrom agresivnosti. Na slici ispod prikazani su rezultati modifikacije PA algoritma u slučaju klasifikacije, sa leve strane je `PA-I`, a sa desne `PA-II`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54024c",
   "metadata": {},
   "source": [
    "<img src='assets/PA_modifications.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266ea4db",
   "metadata": {},
   "source": [
    "Za rad sa pasivno-agresivnim algoritmima za klasifikaciju možemo koristiti klasu [PassiveAggressiveClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveClassifier.html) modula `linear_model` biblioteke `sklearn` sa parametrom `loss`= **hinge** (PA-I) ili `loss` = **squared_hinge** (PA-II).\n",
    "Slično, klasu [PassiveAggressiveRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PassiveAggressiveRegressor.html) možemo koristiti za rad sa pasivno-agresivnim algoritmima za regresiju sa parametrom `loss`= **epsilon_insensitive** (PA-I) ili `loss` = **squared_epsilon_insensitive** (PA-II)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e42c4db",
   "metadata": {},
   "source": [
    "Izvor: [Online Passive-Aggressive Algorithms.pdf](https://jmlr.csail.mit.edu/papers/volume7/crammer06a/crammer06a.pdf), [Online Passive-Aggressive Algorithms.ppt](https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fhome.ttic.edu%2F~shai%2Fppt%2FPassiveAggressive.ppt&wdOrigin=BROWSELINK) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
